# Статистика и не только {#statistics_and_more}

ываываыв
ываываыв

## Генерирование случайных величин {#random_variables}

Для решения задач по теории вероятностей или исследования свойств статистических алгоритмов может потребоваться сгененировать случайную выборку из заданного закона распределения.

Генерируем 10 равномерных на отрезке $[4;10.5]$ случайных величин:
```{r}
x <- runif(10, min = 4, max = 10.5)
```

Генерируем 10 нормальных $N(2;9)$ случайных величин с математическим ожиданием $2$ и дисперсией $9=3^2$:
```{r}
x <- rnorm(10, mean = 2, sd = 3)
```

Например, с помощью симуляций легко оценить математическое ожидание $E(1/X)$, где $X \sim N(2;9)$. Для этого мы вспомним Закон Больших Чисел. Он говорит, что арифметическое среднее по большой выборке стремится по вероятности и почти наверное к математическому ожиданию. Поэтому мы просто сгенерируем большую выборку в миллион наблюдений:

```{r}
n_obs <- 10^6
x <- rnorm(n_obs, mean = 2, sd = 3)
mean(1/x)
```

Также легко оценить многие вероятности. Например, оценим вероятность $P(X_1 + X_2 + X_3^2 > 5)$, где величины $X_i$ независимы и одинаково распределены $X_i \sim U[0;2]$:
```{r}
n_obs <- 10^6
x_1 <- runif(n_obs, min = 0, max = 2)
x_2 <- runif(n_obs, min = 0, max = 2)
x_3 <- runif(n_obs, min = 0, max = 2)
success <- x_1 + x_2 + x_3^2 > 5
sum(success) / n_obs
```

Здесь вектор `success` будет содержать значение TRUE там, где условие `x_1 + x_2 + x_3^2 > 5` выполнено, и FALSE  там, где условие не выполнено. При сложении командой `sum()` каждое TRUE будет посчитано как единица, а каждое FALSE как ноль. Поэтому `sum(success)` даст количество раз, когда условие `x_1 + x_2 + x_3^2 > 5` выполнено.



... тут ещё несколько распределений



... помимо генерации случайных чисел нарисуем функции плотности и распределения






Если выполнить команду `rnorm(10, mean = 2, sd = 3)` на двух разных компьютерах или два раза на одном и том же, то результат будет разный. Не зря же они случайные :) Однако генерирование случайных величин никак не противоречит идее абсолютно точной воспроизводимости исследований. Для того, чтобы получились одинаковые результаты, необходимо синхронизировать генераторы случайных чисел на этих двух компьютерах. Делается это путём задания **зерна генератора** (seed). Зерно также называют стартовым значением. В качестве зерна подойдёт любое целое число.

И в результате запуска кода
```{r}
set.seed(42)
rnorm(1, mean = 2, sd = 3)
```

все компьютеры выведут число $6.112875$.

**Если код содержит генерерирование случайных чисел, то для воспроизводимости результатов необходимо задавать зерно генератора**




## Базовые статистические тесты {#statistical_tests}

...

## Множественная регрессия {#classic_regression}

...

## Квантильная регрессия {#quantile_regression}

Незаслуженно забытой оказывается квантильная регрессия. Коэнкер (ссылка) утверждает, что развитие эконометрики началось именно с квантильной регрессии. Для оценок квантильной регрессии не существует формул в явном виде, поэтому она проиграла классической регрессии среднего с формулой $\hat\beta = (X'X)^{-1}X'y$. Сейчас компьютер позволяет начихать на отсутствие явных формул :)

...

## Инструментальные переменные {#instrumental_variables}

...



## Гетероскедастичность {#heteroskedasticity}

...


## Работа с качественными переменными {#factor_variables}

...


## Логит и пробит с визуализацией {#logit_probit}

...


## Метод главных компонент {#pca}

...


## Мультиколлинеарность {#multicollinearity}

...


## LASSO {#lasso}

...


## Метод максимального правдоподобия {#maximum_likelihood}

...


## Метод опорных векторов {#svm}

...


## Случайный лес {#random_forest}

...


## Экспоненциальное сглаживание {#exponential_smoothing}

...


## ARMA модели {#arma}

...


## GARCH {#garch}

...


## VAR и BVAR {#var_bvar}

...



Я не верю в пользу от структурных BVAR, поэтому их здесь нет :)

## Панельные данные {#panel_data}

...



## Байесовский подход: первые шаги {#bayesian_first_steps}

...


## Байесовский подход: STAN {#stan}

...


## Карты {#maps}

> Где карта, Билли?

## Дифференциальные уравнения {#differential_equations}

...


## Задачи оптимизации {#optimisation}

...





