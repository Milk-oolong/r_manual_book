# Статистика и не только {#statistics_and_more}

ываываыв
ываываыв

## Генерирование случайных величин {#random_variables}

Для решения задач по теории вероятностей или исследования свойств статистических алгоритмов может потребоваться сгененировать случайную выборку из заданного закона распределения.

Генерируем 10 равномерных на отрезке $[4;10.5]$ случайных величин:
```{r, "runif_10_4_105"}
runif(10, min = 4, max = 10.5)
```

Генерируем 10 нормальных $N(2;9)$ случайных величин с математическим ожиданием $2$ и дисперсией $9=3^2$:
```{r, "rnorm_10_2_3"}
rnorm(10, mean = 2, sd = 3)
```

Например, с помощью симуляций легко оценить математическое ожидание $E(1/X)$, где $X \sim N(2;9)$. Для этого мы вспомним Закон Больших Чисел. Он говорит, что арифметическое среднее по большой выборке стремится по вероятности и почти наверное к математическому ожиданию. Поэтому мы просто сгенерируем большую выборку в миллион наблюдений:

```{r, "mean_estimation"}
n_obs <- 10^6
x <- rnorm(n_obs, mean = 2, sd = 3)
mean(1/x)
```

Также легко оценить многие вероятности. Например, оценим вероятность $P(X_1 + X_2 + X_3^2 > 5)$, где величины $X_i$ независимы и одинаково распределены $X_i \sim U[0;2]$:
```{r, "probability_estimation"}
n_obs <- 10^6
x_1 <- runif(n_obs, min = 0, max = 2)
x_2 <- runif(n_obs, min = 0, max = 2)
x_3 <- runif(n_obs, min = 0, max = 2)
success <- x_1 + x_2 + x_3^2 > 5
sum(success) / n_obs
```

Здесь вектор `success` будет содержать значение TRUE там, где условие `x_1 + x_2 + x_3^2 > 5` выполнено, и FALSE  там, где условие не выполнено. При сложении командой `sum()` каждое TRUE будет посчитано как единица, а каждое FALSE как ноль. Поэтому `sum(success)` даст количество раз, когда условие `x_1 + x_2 + x_3^2 > 5` выполнено.


С любым распределением `[xxx]` в R связано четыре функции: `r[xxx]`, `d[xxx]`, `p[xxx]` и `q[xxx]`. Для примера возьмём нормальное распределение $N(2;9)$:

- Функция для создания случайной выборки из нормального $N(2; 9)$ распределения --- `rnorm`:
```{r, "rxxx"}
x <- rnorm(100, mean = 2, sd = 3) # случайная выборка из 100 нормальных N(2; 9) величин
head(x, 10) # первые 10 элементов вектора
```

- Функция плотности --- `dnorm`:
```{r, "normal_pdf_plot"}
x <- seq(from = -6, to = 10, length.out = 100)
y <- dnorm(x, mean = 2, sd = 3)
qplot(x = x, y = y, geom = "line") + xlab("Значения случайной величины $X$") + ylab("Функция плотности")
```

Для дискретных распределений с буквы `d` начинается название функции, возвращающей вероятность получить заданное значение. Найдём для случайной величины $W$, имеющей Пуассоновское распределение с параметром $\lambda = 2$ вероятность $P(W = 3)$:
```{r, "poisson_example"}
dpois(3, lambda = 2)
```


- Функция распределения, $F(t)=P(X\leq t)$ --- `pnorm`:
```{r, "normal_cdf_plot"}
x <- seq(from = -6, to = 10, length.out = 100)
y <- pnorm(x, mean = 2, sd = 3)
qplot(x = x, y = y, geom = "line") + xlab("Значения случайной величины $X$") + ylab("Функция распределения")
```

- Квантильная функция или обратная функция распределения, $q(x) = F^{-1}(x)$ --- `qnorm`:

Найдём перцентили 5\%, 15\% и 90\% для нормального $N(2; 9)$ распределения:
```{r, "normal_quantile_function_example"}
x <- c(0.05, 0.15, 0.9)
qnorm(x, mean = 2, sd = 3)
```

Иногда бывает полезно получить случайную выборку из заданного вектора без повторений:
```{r, "simple_random_sample"}
sample(1:100, size = 20)
```


Или с повторениями:
```{r, "sample_with_replacement"}
sample(c("Орёл", "Решка"), size = 10, replace = TRUE)
```

Можно добавить неравные вероятности:
```{r, "sample_with_probabilities"}
sample(c("Орёл", "Решка"), size = 10, replace = TRUE, prob = c(0.3, 0.7))
```


Если выполнить команду `rnorm(10, mean = 2, sd = 3)` на двух разных компьютерах или два раза на одном и том же, то результат будет разный. Не зря же они случайные :) Однако генерирование случайных величин никак не противоречит идее абсолютно точной воспроизводимости исследований. Для того, чтобы получились одинаковые результаты, необходимо синхронизировать генераторы случайных чисел на этих двух компьютерах. Делается это путём задания **зерна** генератора случайных чисел (seed). Зерно также называют **стартовым значением**. В качестве зерна подойдёт любое целое число.

И в результате запуска кода
```{r, "set_seed"}
set.seed(42)
rnorm(1, mean = 2, sd = 3)
```

все компьютеры выведут число $6.112875$.

```{block, type="warning"}
Если код содержит генерерирование случайных чисел, то необходимо задавать зерно генератора случайных чисел!
```



## Базовые статистические тесты {#statistical_tests}

...

## Множественная регрессия {#classic_regression}

...

Эконометристы любят копаться в остатках :)

https://www.r-bloggers.com/visualising-residuals/


## Квантильная регрессия {#quantile_regression}

Незаслуженно забытой оказывается квантильная регрессия. Коэнкер (ссылка) утверждает, что развитие эконометрики началось именно с квантильной регрессии. Для оценок квантильной регрессии не существует формул в явном виде, поэтому она проиграла классической регрессии среднего с формулой $\hat\beta = (X'X)^{-1}X'y$. Сейчас компьютер позволяет начихать на отсутствие явных формул :)

...

## Инструментальные переменные {#instrumental_variables}

Каждый исследователь мечтает обнаружить не просто статистическую связь, а причинно-следственную. К сожалению, это не так просто. Фиксируя количество людей с зонтиками на улице и количество осадков но не зная физическую природу дождя, невозможно определить, вызывают ли люди с зонтиками дождь или наоборот. Для выяснения причинно следственных связей необходим случайный эксперимент. Например, можно выбрать несколько случайных дней в году и выгнать толпу знакомых с зонтами на улицу, а затем посмотреть, было ли больше осадков в эти дни.

Инструментальные переменные часто используются исследователями при поиске причинно следственных связей, но это ни в коем случае не означает, что введение инструментальных переменных само по себе гарантирует нахождение причинно-следственной связи! 

```{block, type="warning"}
Для обнаружения причинно-следственной связи необходимо либо использовать данные случайного эксперимента, либо прекрасно разбираться в закономерностях происходящего.
```

Этот раздел не о том, как обнаружить причинно-следственную связь, а о том, как реализовать метод инструментальных переменных в R и как его проинтепретировать.





## Гетероскедастичность {#heteroskedasticity}

...


## Работа с качественными переменными {#factor_variables}

...


## Логит и пробит с визуализацией {#logit_probit}

...


## Метод главных компонент {#pca}

...


## Мультиколлинеарность {#multicollinearity}

...


## LASSO {#lasso}

...


## Метод максимального правдоподобия {#maximum_likelihood}

...


## Метод опорных векторов {#svm}

...


## Случайный лес {#random_forest}

...


## Экспоненциальное сглаживание {#exponential_smoothing}

...


## ARMA модели {#arma}

...


## GARCH {#garch}

...


## VAR и BVAR {#var_bvar}

...



Я не верю в пользу от структурных BVAR, поэтому их здесь нет :)

## Панельные данные {#panel_data}

...



## Байесовский подход: первые шаги {#bayesian_first_steps}

...


## Байесовский подход: STAN {#stan}

...


## Карты {#maps}

> Где карта, Билли?

## Дифференциальные уравнения {#differential_equations}

...


## Задачи оптимизации {#optimisation}

...





